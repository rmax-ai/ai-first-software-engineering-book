<!DOCTYPE html>

<html data-bs-theme="light" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="Autonomous Authors" name="author"/>
<link href="../../../img/favicon.ico" rel="shortcut icon"/>
<title>03. Autonomous Kernels - AI-First Software Engineering</title>
<link href="../../../css/bootstrap.min.css" rel="stylesheet"/>
<link href="../../../css/fontawesome.min.css" rel="stylesheet"/>
<link href="../../../css/brands.min.css" rel="stylesheet"/>
<link href="../../../css/solid.min.css" rel="stylesheet"/>
<link href="../../../css/v4-font-face.min.css" rel="stylesheet"/>
<link href="../../../css/base.css" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" id="hljs-light" rel="stylesheet"/>
<link disabled="" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" id="hljs-dark" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
</head>
<body>
<div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
<div class="container">
<a class="navbar-brand" href="../../..">AI-First Software Engineering</a>
<!-- Expander button -->
<button aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-bs-target="#navbar-collapse" data-bs-toggle="collapse" type="button">
<span class="navbar-toggler-icon"></span>
</button>
<!-- Expanded navigation -->
<div class="navbar-collapse collapse" id="navbar-collapse">
<!-- Main navigation -->
<ul class="nav navbar-nav">
<li class="nav-item">
<a class="nav-link" href="../../..">Home</a>
</li>
<li class="nav-item">
<a class="nav-link" href="../../preface/">Preface</a>
</li>
<li class="nav-item dropdown">
<a aria-current="page" aria-expanded="false" class="nav-link dropdown-toggle active" data-bs-toggle="dropdown" href="#" role="button">Chapters</a>
<ul class="dropdown-menu">
<li>
<a class="dropdown-item" href="../01-paradigm-shift/">01. Paradigm Shift</a>
</li>
<li>
<a class="dropdown-item" href="../02-harness-engineering/">02. Harness Engineering</a>
</li>
<li>
<a aria-current="page" class="dropdown-item active" href="./">03. Autonomous Kernels</a>
</li>
<li>
<a class="dropdown-item" href="../04-memory-systems/">04. Memory Systems</a>
</li>
<li>
<a class="dropdown-item" href="../05-evaluation-and-traces/">05. Evaluation and Traces</a>
</li>
<li>
<a class="dropdown-item" href="../06-agent-governance/">06. Agent Governance</a>
</li>
<li>
<a class="dropdown-item" href="../07-production-ai-infrastructure/">07. Production AI Infrastructure</a>
</li>
<li>
<a class="dropdown-item" href="../99-future-directions/">99. Future Directions</a>
</li>
</ul>
</li>
<li class="nav-item">
<a class="nav-link" href="../../glossary/">Glossary</a>
</li>
<li class="nav-item dropdown">
<a aria-expanded="false" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button">Patterns Overview</a>
<ul class="dropdown-menu">
<li>
<a class="dropdown-item" href="../../patterns/harness-design-patterns/">Harness Design</a>
</li>
<li>
<a class="dropdown-item" href="../../patterns/memory-architectures/">Memory Architectures</a>
</li>
<li>
<a class="dropdown-item" href="../../patterns/minimal-agent-loop/">Minimal Agent Loop</a>
</li>
<li>
<a class="dropdown-item" href="../../patterns/self-verification-loop/">Self-Verification Loop</a>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav ms-md-auto">
<li class="nav-item">
<a class="nav-link" data-bs-target="#mkdocs_search_modal" data-bs-toggle="modal" href="#">
<i class="fa fa-search"></i> Search
                            </a>
</li>
<li class="nav-item">
<a class="nav-link" href="../02-harness-engineering/" rel="prev">
<i class="fa fa-arrow-left"></i> Previous
                                </a>
</li>
<li class="nav-item">
<a class="nav-link" href="../04-memory-systems/" rel="next">
                                    Next <i class="fa fa-arrow-right"></i>
</a>
</li>
</ul>
</div>
</div>
</div>
<div class="container">
<div class="row">
<div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
<div class="navbar-header">
<button class="navbar-toggler collapsed" data-bs-target="#toc-collapse" data-bs-toggle="collapse" title="Table of Contents" type="button">
<span class="fa fa-angle-down"></span>
</button>
</div>
<div class="navbar-collapse collapse card bg-body-tertiary" id="toc-collapse">
<ul class="nav flex-column">
<li class="nav-item" data-bs-level="1"><a class="nav-link" href="#chapter-03-autonomous-kernels">Chapter 03 — Autonomous Kernels</a>
<ul class="nav flex-column">
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#thesis">Thesis</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#why-this-matters">Why This Matters</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#system-breakdown">System Breakdown</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#concrete-example-1">Concrete Example 1</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#concrete-example-2">Concrete Example 2</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#trade-offs">Trade-offs</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#failure-modes">Failure Modes</a>
<ul class="nav flex-column">
</ul>
</li>
<li class="nav-item" data-bs-level="2"><a class="nav-link" href="#research-directions">Research Directions</a>
<ul class="nav flex-column">
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div></div>
<div class="col-md-9" role="main">
<h1 id="chapter-03-autonomous-kernels">Chapter 03 — Autonomous Kernels</h1>
<h2 id="thesis">Thesis</h2>
<p>An autonomous kernel is a minimal, well-specified control loop that executes bounded work: plan, apply tool actions, verify, and stop. Its constraints (budgets, permissions, evaluation gates) define a safety envelope that makes outcomes inspectable and repeatable.</p>
<p>Definitions:
- <strong>Autonomous kernel</strong>: a control loop with explicit limits and explicit exit criteria; it is not “general autonomy,” long-horizon project management, or open-ended exploration.
- <strong>Budget</strong>: a hard cap on resources (iterations, elapsed time, tool calls, diff size) that prevents runaway behavior and forces escalation when progress stalls.
- <strong>Evaluation gate</strong>: a required check whose result must be recorded and must be satisfied (or explicitly waived with justification) before the kernel can declare success.</p>
<p>Hypothesis: small, well-governed autonomous kernels (tight loops with explicit budgets and evaluation gates) outperform broad autonomy in stability and debuggability.</p>
<h2 id="why-this-matters">Why This Matters</h2>
<ul>
<li>Most failures in agentic work are operational: runaway loops, untraceable edits, and unverifiable outcomes.</li>
<li>Kernels enable composability: multiple kernels can run with different permissions and evaluation profiles.</li>
<li>“Kernel-first” design makes autonomy a system property, not a prompt trick.</li>
</ul>
<h2 id="system-breakdown">System Breakdown</h2>
<ul>
<li><strong>Kernel loop</strong>: intent → plan → act → verify → record trace → stop/iterate.</li>
<li><strong>Budgets</strong>: max iterations, time, tool calls, diff size.</li>
<li><strong>Permissions</strong>: read/write scopes, protected paths, allowed tools.</li>
<li><strong>Verification</strong>: mandatory checks per action class (e.g., tests for code changes).</li>
<li><strong>Persistence</strong>: ledger entries, trace logs, artifacts.</li>
</ul>
<p>To make this operational, treat each loop step as a checkpoint with a “must record” trace payload and a “must decide” stop condition:
- <strong>Intent</strong>: state the task class and success condition (e.g., “tests pass,” “build passes,” “repro no longer fails”).
- <strong>Plan</strong>: enumerate the next 1–3 actions only (not the whole project), each tied to a verification gate and a budget slice.
- <strong>Act</strong>: perform the minimal change that addresses the current hypothesis; avoid speculative edits that cannot be evaluated.
- <strong>Verify</strong>: run the smallest evaluation that is credible for the task class. Use unit tests for logic changes and typecheck/build for dependency changes; use end-to-end only when required. Verification can fail in two ways: the check fails, or the check is too narrow to detect the real regression.
- <strong>Record trace</strong>: persist commands executed, files touched, diff stats, and evaluation outputs (or hashes/pointers to them) so a human can replay or audit.
- <strong>Stop/iterate</strong>: stop when the success condition is met, or when a budget is exhausted, or when verification indicates the current plan cannot succeed without broader permissions/scope.</p>
<p>Mermaid mapping of stages to controls and outputs:</p>
<div class="mermaid">flowchart LR
  I[Intent] --&gt; P[Plan] --&gt; A[Act] --&gt; V[Verify] --&gt; R[Record trace] --&gt; S{Stop / iterate}

  B[(Budgets\niterations/time/tool calls/diff size)] -. constrains .-&gt; P
  B -. constrains .-&gt; A
  B -. constrains .-&gt; V
  Perm[(Permissions\nread/write scopes\nprotected paths\nallowed tools)] -. constrains .-&gt; A
  Gate[(Evaluation gates\nby action class)] -. required .-&gt; V
  Persist[(Persistence\nledger/trace logs/artifacts)] -. produced .-&gt; R

  V --&gt;|pass| S
  V --&gt;|fail| P
  S --&gt;|iterate| P
  S --&gt;|stop| End[Exit with summary]
</div>
<p>A compact “must capture” checklist (minimum viable trace):
| Loop stage | Budget signal | Permission signal | Verification signal | Persistence artifact |
|---|---|---|---|---|
| intent | remaining iterations/time | required read scope | success criteria defined | intent string + criteria |
| plan | tool-call budget allocation | allowed tools list | planned gates named | plan steps + gate mapping |
| act | diff size consumed | write scope used | N/A | patch/diff stats |
| verify | time/tool calls consumed | execution permissions | gate results (pass/fail) | command + exit code + excerpt |
| record trace | N/A | N/A | N/A | ledger entry + trace pointer |
| stop/iterate | budget exhausted? | permission insufficient? | gates satisfied? | final summary + next action |</p>
<h2 id="concrete-example-1">Concrete Example 1</h2>
<p>Bug-fix kernel for a CLI tool.</p>
<ul>
<li>Input:</li>
<li>failing test case: <code>tests/test_parse.py::test_rejects_empty_input</code></li>
<li>reproduction step: <code>python -m mycli parse ""</code> returns exit code <code>0</code> but should return non-zero</li>
<li>budgets: max 3 iterations, max 10 tool calls, max 40 lines changed</li>
<li>permissions: read <code>src/</code>, write <code>src/parser.py</code>, run <code>pytest -k parse</code></li>
</ul>
<p>Mini-runbook (a single bounded kernel run):
1. Localize failure (evidence-first)
   - Action: run the smallest check that reproduces the failure.
     - Command: <code>pytest -k rejects_empty_input</code>
   - Record:
     - failing assertion excerpt (placeholder): <code>E assert 0 == 2</code>
     - environment notes: OS, Python version, CLI args
   - Stop/iterate rule:
     - If the failure does not reproduce, stop and return “cannot reproduce” trace (do not edit).</p>
<ol>
<li>Patch minimal surface (hypothesis-driven)</li>
<li>Hypothesis: empty string is being treated as a valid token stream in <code>src/parser.py</code>.</li>
<li>Action: make a minimal edit that rejects empty input at the boundary (not across unrelated call sites).</li>
<li>Budget check:<ul>
<li>ensure diff size stays within 40 lines and touches only <code>src/parser.py</code> (or a single adjacent file if necessary).</li>
</ul>
</li>
<li>
<p>Record:</p>
<ul>
<li>files touched: <code>src/parser.py</code></li>
<li>diff stats: <code>+6 -1</code> (placeholder)</li>
</ul>
</li>
<li>
<p>Run verification gate (tight but credible)</p>
</li>
<li>Gate 1: rerun the failing test.<ul>
<li>Command: <code>pytest -k rejects_empty_input</code></li>
</ul>
</li>
<li>Gate 2 (cheap regression check): run related unit tests only.<ul>
<li>Command: <code>pytest -k parse</code></li>
</ul>
</li>
<li>
<p>Verification risk handling:</p>
<ul>
<li>If Gate 1 passes but Gate 2 fails, treat as “not fixed” (the patch likely broke a nearby invariant).</li>
</ul>
</li>
<li>
<p>Record trace (auditable, replayable)</p>
</li>
<li>Persist a kernel trace with:<ul>
<li>budgets consumed: iterations used, tool calls used, diff size</li>
<li>commands executed + exit codes</li>
<li>final test summary line (placeholder): <code>2 passed, 0 failed</code></li>
</ul>
</li>
<li>
<p>Write a ledger entry summarizing:</p>
<ul>
<li>what changed (one-sentence)</li>
<li>why it changed (link to failing assertion)</li>
<li>what verified it (gate list)</li>
</ul>
</li>
<li>
<p>Stop criteria (explicit)</p>
</li>
<li>Stop success: Gate 1 and Gate 2 pass within budget.</li>
<li>Stop failure: tool-call budget exhausted, diff budget exceeded, or verification indicates a broader refactor is required.</li>
<li>Stop escalation output: include “next action for a human” (e.g., “needs design change in tokenization; requires editing <code>src/lexer.py</code>, which is outside current write scope”).</li>
</ol>
<h2 id="concrete-example-2">Concrete Example 2</h2>
<p>Dependency upgrade kernel.</p>
<ul>
<li>Input:</li>
<li>target version: <code>libX 4.2.0 → 4.3.0</code></li>
<li>constraints: Python <code>&gt;=3.10</code>, cannot change public API, CI must stay green</li>
<li>upgrade guide: notes a breaking rename <code>OldClient</code> → <code>Client</code></li>
<li>budgets: max 4 iterations, max 15 tool calls, max 120 lines changed</li>
<li>permissions: write <code>pyproject.toml</code> and <code>src/</code>, run <code>python -m compileall</code> and <code>pytest</code></li>
</ul>
<p>Kernel steps with an explicit remediation branch:
1. Update manifest (narrow scope)
   - Action: bump version constraint in <code>pyproject.toml</code>.
   - Record:
     - old/new constraint strings
     - diff stats for manifest only
   - Stop/iterate rule:
     - If the dependency resolver cannot produce a consistent lock, stop with resolver output (do not attempt ad-hoc pinning unless that is explicitly in scope).</p>
<ol>
<li>Run a fast build/type gate before full tests</li>
<li>Gate A (fast): import/type/compile smoke check.<ul>
<li>Command: <code>python -m compileall src</code></li>
</ul>
</li>
<li>Record:<ul>
<li>exit code</li>
<li>compile summary line (placeholder): <code>Listing 'src'...</code> … <code>compileall: success</code> (or equivalent)</li>
</ul>
</li>
<li>
<p>Interpretation:</p>
<ul>
<li>If Gate A fails, this is often a missing symbol or incompatible API that will be faster to remediate than running the full suite.</li>
</ul>
</li>
<li>
<p>Remediation branch (compile errors vs failing tests)</p>
</li>
<li>If <strong>compile/import fails</strong>:<ul>
<li>Localize: identify first error site (file + symbol).</li>
<li>Patch: apply the minimal mechanical fix (e.g., rename <code>OldClient</code> to <code>Client</code>) in the smallest set of files.</li>
<li>Verify: rerun Gate A only, then proceed.</li>
<li>Budget guard:</li>
<li>If more than 5 files are touched, stop and escalate (“requires broader refactor”).</li>
<li>If the cumulative diff exceeds 120 lines changed, stop and escalate (“exceeds change budget for this kernel”).</li>
</ul>
</li>
<li>
<p>If <strong>compile passes but tests fail</strong>:</p>
<ul>
<li>Localize: run the single failing test file or test case.</li>
<li>Patch: address behavioral change (e.g., new default timeout) with a targeted adjustment and a justification in the trace.</li>
<li>Verify: rerun the failing tests, then run the full relevant suite.</li>
</ul>
</li>
<li>
<p>Run full verification gate (credibility gate)</p>
</li>
<li>Gate B (full): run the test suite (or the project’s standard verification command).<ul>
<li>Command: <code>pytest</code></li>
</ul>
</li>
<li>Record:<ul>
<li>exit code</li>
<li>test summary line (placeholder): <code>X passed, 0 failed</code> (or, on failure, <code>X passed, Y failed</code>)</li>
</ul>
</li>
<li>
<p>Verification risk handling:</p>
<ul>
<li>Treat a narrowed verification set as a failure mode unless the trace records why it is acceptable (e.g., “no integration tests exist; unit suite is the highest available gate”).</li>
</ul>
</li>
<li>
<p>Stop criteria and outputs</p>
</li>
<li>Stop success: Gate A and Gate B pass within budget.</li>
<li>Stop failure: repeated failures indicate the upgrade exceeds current permission/scope (e.g., requires API redesign), or budgets are exhausted.</li>
<li>Required outputs on stop:<ul>
<li>change summary: files touched + primary reason</li>
<li>verification summary: Gate A command + result and Gate B command + result, including summary lines</li>
<li>rollback plan: “revert manifest bump and lockfile” (or equivalent) with the exact files to revert</li>
</ul>
</li>
</ol>
<h2 id="trade-offs">Trade-offs</h2>
<ul>
<li>Smaller kernels reduce risk but may require orchestration for multi-step projects.</li>
<li>Mitigation: use staged kernels (e.g., “diagnose-only” kernel → “patch” kernel → “refactor” kernel), each with separate budgets and permissions.</li>
<li>Strict permissions reduce blast radius but can prevent necessary refactors.</li>
<li>Mitigation: use permission escalation as an explicit step with a justification and a widened verification gate (e.g., requiring a broader test suite when write scope expands).</li>
<li>Heavier tracing improves auditability but adds operational overhead.</li>
<li>Mitigation: record a minimum viable trace by default (commands, diffs, gate results), and sample/expand traces only on failures or high-risk task classes.</li>
</ul>
<h2 id="failure-modes">Failure Modes</h2>
<ul>
<li><strong>Local minima</strong>: kernel makes safe micro-edits without addressing root cause.</li>
<li><strong>Tool thrash</strong>: too many actions with low information gain.</li>
<li><strong>False confidence</strong>: passing a narrow eval set while violating higher-level requirements.</li>
</ul>
<p>Detection signals (tie these to budgets and evaluation gates, not intuition):
- Local minima:
  - repeated edits in the same small area with no change in verification outcome across iterations
  - steadily increasing diff size without new evidence (no new failing test localized, no new reproduction)
- Tool thrash:
  - tool-call count rising while the plan does not change (same commands rerun without a new hypothesis)
  - frequent context switches (many files touched) despite a small, bounded intent
- False confidence:
  - verification gates becoming narrower over time (“only reran one test”) without a recorded justification
  - “green” on fast gates but repeated regressions reported elsewhere (signals the gate set is mis-specified for the task class)
  - success declared without a trace artifact that includes gate results and the exact commands used</p>
<h2 id="research-directions">Research Directions</h2>
<ul>
<li>Kernel composition patterns (delegation, staged permissions, multi-kernel workflows).</li>
<li>Automatic stop-condition tuning based on task class.</li>
<li>Replayable kernels for deterministic debugging of agent behavior.</li>
</ul></div>
</div>
</div>
<footer class="col-md-12">
<hr/>
<p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
</footer>
<script src="../../../js/bootstrap.bundle.min.js"></script>
<script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
<script src="../../../js/base.js"></script>
<script src="../../../search/main.js"></script>
<div aria-hidden="true" aria-labelledby="searchModalLabel" class="modal" id="mkdocs_search_modal" role="dialog" tabindex="-1">
<div class="modal-dialog modal-lg">
<div class="modal-content">
<div class="modal-header">
<h4 class="modal-title" id="searchModalLabel">Search</h4>
<button aria-label="Close" class="btn-close" data-bs-dismiss="modal" type="button"></button>
</div>
<div class="modal-body">
<p>From here you can search these documents. Enter your search terms below.</p>
<form>
<div class="form-group">
<input class="form-control" id="mkdocs-search-query" placeholder="Search..." title="Type search term here" type="search"/>
</div>
</form>
<div data-no-results-text="No results found" id="mkdocs-search-results"></div>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div><div aria-hidden="true" aria-labelledby="keyboardModalLabel" class="modal" id="mkdocs_keyboard_modal" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
<button aria-label="Close" class="btn-close" data-bs-dismiss="modal" type="button"></button>
</div>
<div class="modal-body">
<table class="table">
<thead>
<tr>
<th style="width: 20%;">Keys</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td class="help shortcut"><kbd>?</kbd></td>
<td>Open this help</td>
</tr>
<tr>
<td class="next shortcut"><kbd>n</kbd></td>
<td>Next page</td>
</tr>
<tr>
<td class="prev shortcut"><kbd>p</kbd></td>
<td>Previous page</td>
</tr>
<tr>
<td class="search shortcut"><kbd>s</kbd></td>
<td>Search</td>
</tr>
</tbody>
</table>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div>
<script type="module">import mermaid from "https://unpkg.com/mermaid@10.4.0/dist/mermaid.esm.min.mjs";
mermaid.initialize({});</script></body>
</html>
